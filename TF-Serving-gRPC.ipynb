{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:25:07.999444Z",
     "start_time": "2020-04-28T02:25:07.990962Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import platform\n",
    "\n",
    "import grpc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:13:11.434527Z",
     "start_time": "2020-04-28T02:13:11.431782Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF-Serving gRPC informations: https://github.com/tensorflow/serving/blob/master/tensorflow_serving\n",
    "# Docker informations: https://www.docker.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:13:14.919321Z",
     "start_time": "2020-04-28T02:13:11.672131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current OS: \n",
      "    Darwin-18.7.0-x86_64-i386-64bit\n",
      "\n",
      "Docker version: \n",
      "    19.03.8, build afacb8b\n"
     ]
    }
   ],
   "source": [
    "# Check OS informations, docker version\n",
    "\n",
    "resp = !docker --version\n",
    "docker_version = ' '.join(resp[0].split(' ')[2:])\n",
    "print(\"Current OS: \\n\"\n",
    "      \"    {}\\n\".format(platform.platform()))\n",
    "print(\"Docker version: \\n\"\n",
    "      \"    {}\".format(docker_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:35:59.591624Z",
     "start_time": "2020-04-28T02:35:59.384232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare testing data\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(_, _), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:13:15.173463Z",
     "start_time": "2020-04-28T02:13:15.169196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images numbers:\n",
      "     Test : 10000\n",
      "Image size: 28 * 28\n"
     ]
    }
   ],
   "source": [
    "# Print MNIST dataset informations\n",
    "# 打印 MNIST 資料集相關資訊\n",
    "\n",
    "print(\"Images numbers:\\n\"\n",
    "        \"     Test : {}\".format(x_test.shape[0]))\n",
    "print(\"Image size: {} * {}\".format(x_test.shape[1:][0], x_test.shape[1:][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:13:21.587105Z",
     "start_time": "2020-04-28T02:13:18.183987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\r\n"
     ]
    }
   ],
   "source": [
    "# Pull tf-serving latest official image from docker hub \n",
    "# Or use !docker pull tensorflow/serving:1.12.0 to pull specific version\n",
    "# Use gpu with tensorflow/serving:latest-gpu\n",
    "# 從 docker hub 拉取最新的 tf-serving 映像檔\n",
    "# 或是使用 !docker pull tensorflow/serving:1.12.0 拉取特定版本\n",
    "# Gpu 版本請用 tensorflow/serving:latest-gpu\n",
    "\n",
    "!docker pull tensorflow/serving:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run serving docker, better not run this shit in IPython notebook\n",
    "# Port 8501 exposed for RESTful API, Port 8500 exposed for gRPC\n",
    "# 請打開一個終端已架設 serving docker，別使用 IPython notebook\n",
    "\n",
    "!$MODELPATH = \"Your models folder path ... must be absolute path!\"\n",
    "!docker run -t --rm -p 8500:8500 \\\n",
    "    --mount type=bind,source=$MODELPATH,target=/models \\\n",
    "    -e MODEL_NAME=mnist \\\n",
    "    --name serving_test \\\n",
    "    tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:17:57.435607Z",
     "start_time": "2020-04-28T02:17:57.286359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      " \"model_version_status\": [\r\n",
      "  {\r\n",
      "   \"version\": \"1\",\r\n",
      "   \"state\": \"AVAILABLE\",\r\n",
      "   \"status\": {\r\n",
      "    \"error_code\": \"OK\",\r\n",
      "    \"error_message\": \"\"\r\n",
      "   }\r\n",
      "  }\r\n",
      " ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# You can get informations of served model with API after you successfully ran a serving docker\n",
    "# 如果成功跑起一個 serving docker，可以用 API 取得模型資訊\n",
    "\n",
    "!curl http://localhost:8501/v1/models/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:17:58.639416Z",
     "start_time": "2020-04-28T02:17:58.614960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"model_version_status\": [\n",
      "  {\n",
      "   \"version\": \"1\",\n",
      "   \"state\": \"AVAILABLE\",\n",
      "   \"status\": {\n",
      "    \"error_code\": \"OK\",\n",
      "    \"error_message\": \"\"\n",
      "   }\n",
      "  }\n",
      " ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One of the key advantages of REST APIs is that they provide a great deal of flexibility\n",
    "# Data is not tied to resources or methods, so REST can handle multiple types of calls\n",
    "# Use python request lib\n",
    "\n",
    "resp = requests.get('http://localhost:8501/v1/models/mnist')\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:17:58.944902Z",
     "start_time": "2020-04-28T02:17:58.932679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: \n",
      "         <Response [200]>\n",
      "Respones: \n",
      "         {\n",
      "\"model_spec\":{\n",
      " \"name\": \"mnist\",\n",
      " \"signature_name\": \"\",\n",
      " \"version\": \"1\"\n",
      "}\n",
      ",\n",
      "\"metadata\": {\"signature_def\": {\n",
      " \"signature_def\": {\n",
      "  \"serving_default\": {\n",
      "   \"inputs\": {\n",
      "    \"flatten_input\": {\n",
      "     \"dtype\": \"DT_FLOAT\",\n",
      "     \"tensor_shape\": {\n",
      "      \"dim\": [\n",
      "       {\n",
      "        \"size\": \"-1\",\n",
      "        \"name\": \"\"\n",
      "       },\n",
      "       {\n",
      "        \"size\": \"28\",\n",
      "        \"name\": \"\"\n",
      "       },\n",
      "       {\n",
      "        \"size\": \"28\",\n",
      "        \"name\": \"\"\n",
      "       }\n",
      "      ],\n",
      "      \"unknown_rank\": false\n",
      "     },\n",
      "     \"name\": \"serving_default_flatten_input:0\"\n",
      "    }\n",
      "   },\n",
      "   \"outputs\": {\n",
      "    \"dense_1\": {\n",
      "     \"dtype\": \"DT_FLOAT\",\n",
      "     \"tensor_shape\": {\n",
      "      \"dim\": [\n",
      "       {\n",
      "        \"size\": \"-1\",\n",
      "        \"name\": \"\"\n",
      "       },\n",
      "       {\n",
      "        \"size\": \"10\",\n",
      "        \"name\": \"\"\n",
      "       }\n",
      "      ],\n",
      "      \"unknown_rank\": false\n",
      "     },\n",
      "     \"name\": \"StatefulPartitionedCall:0\"\n",
      "    }\n",
      "   },\n",
      "   \"method_name\": \"tensorflow/serving/predict\"\n",
      "  },\n",
      "  \"__saved_model_init_op\": {\n",
      "   \"inputs\": {},\n",
      "   \"outputs\": {\n",
      "    \"__saved_model_init_op\": {\n",
      "     \"dtype\": \"DT_INVALID\",\n",
      "     \"tensor_shape\": {\n",
      "      \"dim\": [],\n",
      "      \"unknown_rank\": true\n",
      "     },\n",
      "     \"name\": \"NoOp\"\n",
      "    }\n",
      "   },\n",
      "   \"method_name\": \"\"\n",
      "  }\n",
      " }\n",
      "}\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model metadata that we can easily know the signatures in model\n",
    "\n",
    "resp = requests.get('http://localhost:8501/v1/models/mnist/metadata')\n",
    "print(\"Status code: \\n\"\n",
    "      \"         {}\".format(resp))\n",
    "print(\"Respones: \\n\"\n",
    "      \"         {}\".format(resp.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T02:36:13.713770Z",
     "start_time": "2020-04-28T02:36:13.704009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs {\n",
      "  key: \"dense_1\"\n",
      "  value {\n",
      "    dtype: DT_FLOAT\n",
      "    tensor_shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "      dim {\n",
      "        size: 10\n",
      "      }\n",
      "    }\n",
      "    float_val: 0.11874900013208389\n",
      "    float_val: 0.03669405356049538\n",
      "    float_val: 0.06553603708744049\n",
      "    float_val: 0.09101864695549011\n",
      "    float_val: 0.05833970382809639\n",
      "    float_val: 0.06880989670753479\n",
      "    float_val: 0.04713801294565201\n",
      "    float_val: 0.04002722352743149\n",
      "    float_val: 0.35213395953178406\n",
      "    float_val: 0.12155339866876602\n",
      "  }\n",
      "}\n",
      "model_spec {\n",
      "  name: \"mnist\"\n",
      "  version {\n",
      "    value: 1\n",
      "  }\n",
      "  signature_name: \"serving_default\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostport ='localhost:8500'\n",
    "channel = grpc.insecure_channel(hostport)\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "for i in range(1):\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name ='mnist'\n",
    "    request.model_spec.signature_name ='serving_default'\n",
    "    request.inputs['flatten_input'].CopyFrom(tf.make_tensor_proto(x_test[i], shape=[1,1,28, 28]))\n",
    "    result = stub.Predict(request)\n",
    "    print(result)\n",
    "    end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
